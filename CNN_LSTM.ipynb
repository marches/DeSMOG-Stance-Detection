{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mve7MinqPd0"
      },
      "source": [
        "### Static Embeddings\n",
        "In this notebook, we examine teh CNN LSTM approach using static embeddings for classification https://www.sciencedirect.com/science/article/pii/S2667096820300070\n",
        "\n",
        "\n",
        "https://stackabuse.com/python-for-nlp-movie-sentiment-analysis-using-deep-learning-in-keras/\n",
        "\n",
        "https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
        "\n",
        "https://jaketae.github.io/study/word2vec/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWti6Yg7TtQ2"
      },
      "outputs": [],
      "source": [
        "!pip install gensim==3.8.3 --quiet\n",
        "!pip install tensorflow-datasets --quiet\n",
        "!pip install -U tensorflow-text==2.8.2 --quiet\n",
        "!pip install pydot --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03TXq1VkTqD6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import sklearn as sk\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk.data import find\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import gensim\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjN7cebzTYsf",
        "outputId": "740c06fd-73e4-417f-bd34-c21f1cd5bc34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqOSRjSnT3l0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "NOTEBOOK_LOC = \"/content/drive/MyDrive/Colab Notebooks/W266 Final Project/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXpRIEifThyC"
      },
      "source": [
        "### Load Data\n",
        "\n",
        "Also format data for weighted BERT below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phLmnKvPdOHa"
      },
      "outputs": [],
      "source": [
        "TRAIN_TEXTS = []\n",
        "VALID_TEXTS = []\n",
        "\n",
        "TRAIN_LABELS = []\n",
        "VALID_LABELS = []\n",
        "\n",
        "TRAIN_WEIGHTS = []\n",
        "\n",
        "TARGET_NAMES = [\"disagree\", \"neutral\", \"agree\"]\n",
        "\n",
        "CV_IDX = [4]\n",
        "\n",
        "for cv_idx in CV_IDX:\n",
        "\n",
        "  training_data = pd.read_table(NOTEBOOK_LOC + \"/Data/GWSD_training_\"+str(cv_idx)+\".tsv\")\n",
        "  valid_data = pd.read_table(NOTEBOOK_LOC + \"/Data/GWSD_val_\"+str(cv_idx)+\".tsv\")\n",
        "\n",
        "\n",
        "  train_texts = training_data[\"sentence\"].to_list()\n",
        "  train_labels = np.asarray(training_data[\"stance_id\"].astype(int).to_list())\n",
        "\n",
        "  valid_texts = valid_data[\"sentence\"].to_list()\n",
        "  valid_labels = np.asarray(valid_data[\"stance_id\"].astype(int).to_list())\n",
        "\n",
        "  training_data[\"weight\"] = training_data[[\"agree\", \"neutral\", \"disagree\"]].max(axis=1)\n",
        "  train_weights = np.asarray(training_data[\"weight\"]) # add label weights\n",
        "\n",
        "  TRAIN_TEXTS.append(train_texts)\n",
        "  VALID_TEXTS.append(valid_texts)\n",
        "\n",
        "  TRAIN_LABELS.append(train_labels)\n",
        "  VALID_LABELS.append(valid_labels)\n",
        "\n",
        "  TRAIN_WEIGHTS.append(train_weights)\n",
        "\n",
        "test_data = pd.read_table(NOTEBOOK_LOC + \"/Data/GWSD_test.tsv\")\n",
        "test_texts = test_data[\"sentence\"].to_list()\n",
        "test_labels = np.asarray(test_data[\"stance_id\"].astype(int).to_list())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = tf.convert_to_tensor(train_texts, dtype=object)\n",
        "train_labels = tf.convert_to_tensor(train_labels)\n",
        "\n",
        "valid_texts = tf.convert_to_tensor(valid_texts, dtype=object)\n",
        "valid_labels = tf.convert_to_tensor(valid_labels)\n",
        "\n",
        "test_texts = tf.convert_to_tensor(test_texts, dtype=object)\n",
        "test_labels = tf.convert_to_tensor(test_labels)"
      ],
      "metadata": {
        "id": "FxGkZUvQntMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQR43qAPu8aR"
      },
      "source": [
        "### Embedding Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('word2vec_sample')\n",
        "\n",
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlgGa9mi4407",
        "outputId": "c679553e-9af9-4d93-cc9c-a37bcf250daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize embedding matrix and word-to-id map:\n",
        "EMBEDDING_DIM = len(model['university']) \n",
        "\n",
        "embedding_matrix = np.zeros((len(model.vocab.keys()) + 1, EMBEDDING_DIM))       \n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(model.vocab.keys()):\n",
        "    embedding_vector = model[word]\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i"
      ],
      "metadata": {
        "id": "HcaeWt2749UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rNoqHzUs1NW",
        "outputId": "c19f5650-1dbb-4c6e-86bc-e6513bbd7f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0891758 ,  0.121832  , -0.0671959 , ..., -0.0480419 ,\n",
              "        -0.0277889 ,  0.0872918 ],\n",
              "       [ 0.0526281 ,  0.013157  , -0.010104  , ...,  0.0209349 ,\n",
              "        -0.0537912 ,  0.0654217 ],\n",
              "       [ 0.0786419 ,  0.0373911 , -0.0131472 , ..., -0.00832253,\n",
              "        -0.00398034, -0.0825016 ],\n",
              "       ...,\n",
              "       [ 0.0887422 ,  0.0537124 ,  0.0467064 , ..., -0.0794009 ,\n",
              "         0.0945805 , -0.0361975 ],\n",
              "       [-0.011512  ,  0.0173624 , -0.0364862 , ..., -0.0425253 ,\n",
              "         0.0231499 , -0.014217  ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(train_texts)\n",
        "valid_tokens = tokenizer.tokenize(valid_texts)\n",
        "test_tokens = tokenizer.tokenize(test_texts)\n",
        "\n",
        "valid_tokens[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz0gSqG-5SgP",
        "outputId": "f1f88148-4b4d-437a-bcfa-deae11721ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=string, numpy=\n",
              "array([b'City', b'officials', b'city', b'officials', b'decrying',\n",
              "       b'global', b'warming', b'out', b'of', b'one', b'side', b'of',\n",
              "       b'their', b'mouth', b'while', b'downplaying', b'it', b'in',\n",
              "       b'bond', b'disclosures.'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmpF4DtTsMNP",
        "outputId": "b57f5499-5a53-4fd4-a0ab-6a53d0109245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1476, None])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCvbYSp4u_Qm"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 10\n",
        "\n",
        "def sents_to_ids(token_list_list, label_list, num_examples=100000000):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    text_ids = []\n",
        "    text_labels = []\n",
        "    valid_example_list = []\n",
        "    example_count = 0\n",
        "    use_token_list_list = token_list_list[:num_examples]\n",
        "    for i, token_list in enumerate(use_token_list_list):\n",
        "        if i < num_examples:\n",
        "            try:\n",
        "                example = []\n",
        "                for token in list(token_list.numpy()):\n",
        "                    decoded = token.decode('utf-8').replace('.','').replace(',','').replace('!','')\n",
        "                    try:\n",
        "                        example.append(vocab_dict[decoded])\n",
        "                        \n",
        "                    except:\n",
        "                        example.append(43981)\n",
        "                if len(example) >= MAX_SEQUENCE_LENGTH:\n",
        "                    text_ids.append(example[:MAX_SEQUENCE_LENGTH])\n",
        "                    text_labels.append(label_list[i])\n",
        "                    if example_count % 5000 == 0:\n",
        "                        print('Examples processed: ', example_count)\n",
        "                    valid_example_list.append(i) \n",
        "                    example_count += 1\n",
        "                else:\n",
        "                    pass\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    \n",
        "    print('Number of examples retained: ', example_count) \n",
        "    return (np.array(text_ids),   np.array(text_labels), valid_example_list) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_input_labels, train_valid_example_list = sents_to_ids(train_tokens, train_labels)\n",
        "valid_input, valid_input_labels, valid_valid_example_list = sents_to_ids(valid_tokens, valid_labels)\n",
        "test_input, test_input_labels, test_valid_example_list = sents_to_ids(test_tokens, test_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RZ7zXySpTNA",
        "outputId": "a9874424-de97-4e2e-de67-52cfe6111f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples processed:  0\n",
            "Number of examples retained:  1261\n",
            "Examples processed:  0\n",
            "Number of examples retained:  307\n",
            "Examples processed:  0\n",
            "Number of examples retained:  176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simple CNN-LSTM"
      ],
      "metadata": {
        "id": "maeP3zAW6Dhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_lstm_model(learning_rate=0.00005, \n",
        "                          num_filters = [10050, 25],\n",
        "                          kernel_sizes = [3, 5, 10],\n",
        "                          dense_layer_dims = [100, 30],\n",
        "                          dropout_rate = 0.5):\n",
        "  \n",
        "  cnn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)\n",
        "  \n",
        "  cnn_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
        "\n",
        "  cnn_embeddings = cnn_embedding_layer(cnn_input_layer)\n",
        "\n",
        "  h = cnn_embeddings\n",
        "\n",
        "  conv_layers_for_all_kernel_sizes = []\n",
        "  for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
        "      conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(h)\n",
        "      conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
        "      conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
        "\n",
        "  h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
        "  h = keras.layers.Dropout(rate=dropout_rate)(h)\n",
        "\n",
        "  for dense_layer_dim in dense_layer_dims:  \n",
        "    h = keras.layers.Dense(dense_layer_dim, activation='relu')(h)\n",
        "\n",
        "  # x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  x = layers.Bidirectional(tf.keras.layers.LSTM(32))(h)\n",
        "  x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "  classification = tf.keras.layers.Dense(3, activation='softmax',name='classification_layer')(x)\n",
        "\n",
        "  classification_model = tf.keras.Model(inputs=cnn_input_layer, outputs=[classification])\n",
        "  \n",
        "  classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "                          metrics='accuracy') \n",
        "\n",
        "  return classification_model"
      ],
      "metadata": {
        "id": "20_lXSo2ugmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_cnn_lstm_model()\n",
        "keras.utils.plot_model(model, show_shapes=True, dpi=90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "xapTy0zLyjef",
        "outputId": "7e1a9991-bac0-4f89-c2f9-1776672a8ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e64fa5df1acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cnn_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-8f2493d17bf5>\u001b[0m in \u001b[0;36mcreate_cnn_lstm_model\u001b[0;34m(learning_rate, num_filters, kernel_sizes, dense_layer_dims, dropout_rate)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m# x = tf.keras.layers.Dropout(0.2)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[1;32m    215\u001b[0m                          \u001b[0;34m'is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                          \u001b[0;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"bidirectional_5\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 30)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"CNN-LSTM\"\n",
        "EPOCHS = 7\n",
        "\n",
        "for cv_idx in CV_IDX[:]:\n",
        "  model = create_cnn_lstm_model()\n",
        "\n",
        "  print(\"----------------------Training Cross Fold: \" + str(cv_idx) + \"----------------------\")\n",
        "\n",
        "  checkpoint_filepath = 'Models/' + MODEL_NAME + str(cv_idx)\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=checkpoint_filepath,\n",
        "      save_weights_only=True,\n",
        "      monitor='val_accuracy',\n",
        "      mode='max',\n",
        "      save_freq='epoch',\n",
        "      save_best_only=True)\n",
        "\n",
        "  model_history = model.fit(train_input,\n",
        "                            np.array(train_input_labels),\n",
        "                            validation_data=(valid_input, np.array(valid_input_labels)),    \n",
        "                                                  batch_size=16,  \n",
        "                                                  callbacks=[model_checkpoint_callback],\n",
        "                                                  epochs=EPOCHS)\n",
        "  \n",
        "  pd.DataFrame(model_history.history).plot(figsize=(8,5))\n",
        "  plt.title(MODEL_NAME+' CV ' + str(cv_idx))\n",
        "  plt.xlabel('epoch')\n",
        "  plt.savefig(NOTEBOOK_LOC + '/ModelResults/' + MODEL_NAME + str(cv_idx) + \".png\")\n",
        "  plt.show()\n",
        "  \n",
        "  model.load_weights(checkpoint_filepath)\n",
        "  test_predictions = model.predict([test_input, np.array(test_input_labels)]) \n",
        "  print(classification_report(test_labels, np.argmax(test_predictions, axis=1), target_names=TARGET_NAMES))\n",
        "\n",
        "  np.save(NOTEBOOK_LOC + '/ModelResults/TestPredictions' + MODEL_NAME + str(cv_idx), test_predictions, allow_pickle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hyInse7l7P1Q",
        "outputId": "a703520f-bedf-4aa6-8f90-a030611dfa41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------Training Cross Fold: 4----------------------\n",
            "Epoch 1/7\n",
            "79/79 [==============================] - 16s 18ms/step - loss: 1.0871 - accuracy: 0.4330 - val_loss: 1.0880 - val_accuracy: 0.3583\n",
            "Epoch 2/7\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 1.0685 - accuracy: 0.4552 - val_loss: 1.0809 - val_accuracy: 0.3616\n",
            "Epoch 3/7\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0500 - accuracy: 0.4544 - val_loss: 1.0787 - val_accuracy: 0.3616\n",
            "Epoch 4/7\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0343 - accuracy: 0.4544 - val_loss: 1.0818 - val_accuracy: 0.3616\n",
            "Epoch 5/7\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0254 - accuracy: 0.4544 - val_loss: 1.0847 - val_accuracy: 0.3616\n",
            "Epoch 6/7\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0222 - accuracy: 0.4544 - val_loss: 1.0869 - val_accuracy: 0.3616\n",
            "Epoch 7/7\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0184 - accuracy: 0.4544 - val_loss: 1.0871 - val_accuracy: 0.3616\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-daf1d566ebd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTARGET_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_3\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 10) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}